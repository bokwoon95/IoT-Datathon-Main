{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as r\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will swap the rows and columns of a 2x2 list\n",
    "# It uses python's inbuilt zip() function to handle transposition\n",
    "# However zip() returns a list of tuples instead, so this function will convert that back into a list of lists\n",
    "def transpose(lol):\n",
    "    transposedToLot = zip(*lol) #the * asterisk is very important! It prevents zip() from creating a list with a single tuple of tuples\n",
    "    convertedToLol = [list(x) for x in transposedToLot]\n",
    "    return list(convertedToLol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs generated. There are 214 urls.\n"
     ]
    }
   ],
   "source": [
    "a = \"https://www.wunderground.com/history/airport/RCSS/2017/\"\n",
    "b = \"/DailyHistory.html?req_city=New+Taipei+City&req_state=TPQ&req_statename=Taiwan&reqdb.zip=00000&reqdb.magic=5&reqdb.wmo=58968\"\n",
    "\n",
    "urls = [] #contains all the urls that we will be accessing\n",
    "\n",
    "# this loop will populate the url list with the relevant urls\n",
    "for month in range(5,12):\n",
    "    if (month==6 or month==9 or month==11):\n",
    "        for day in range(1,31):\n",
    "            urls.append(a + str(month) + \"/\" + str(day) + b)\n",
    "    else:\n",
    "        for day in range(1,32):\n",
    "            urls.append(a + str(month) + \"/\" + str(day) + b)\n",
    "print(\"URLs generated. There %s %d url%s\" % (\"is\" if len(urls)==1 else \"are\", len(urls), \"\" if len(urls)==1 else \"s.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulsoup boilerplate code\n",
    "opener = r.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/214\n",
      "2/214\n",
      "3/214\n",
      "4/214\n",
      "5/214\n",
      "6/214\n",
      "7/214\n",
      "8/214\n",
      "9/214\n",
      "10/214\n",
      "11/214\n",
      "12/214\n",
      "13/214\n",
      "14/214\n",
      "15/214\n",
      "16/214\n",
      "17/214\n",
      "18/214\n",
      "19/214\n",
      "20/214\n",
      "21/214\n",
      "22/214\n",
      "23/214\n",
      "24/214\n",
      "25/214\n",
      "26/214\n",
      "27/214\n",
      "28/214\n",
      "29/214\n",
      "30/214\n",
      "31/214\n",
      "32/214\n",
      "33/214\n",
      "34/214\n",
      "35/214\n",
      "36/214\n",
      "37/214\n",
      "38/214\n",
      "39/214\n",
      "40/214\n",
      "41/214\n",
      "42/214\n",
      "43/214\n",
      "44/214\n",
      "45/214\n",
      "46/214\n",
      "47/214\n",
      "48/214\n",
      "49/214\n",
      "50/214\n",
      "51/214\n",
      "52/214\n",
      "53/214\n",
      "54/214\n",
      "55/214\n",
      "56/214\n",
      "57/214\n",
      "58/214\n",
      "59/214\n",
      "60/214\n",
      "61/214\n",
      "62/214\n",
      "63/214\n",
      "64/214\n",
      "65/214\n",
      "66/214\n",
      "67/214\n",
      "68/214\n",
      "69/214\n",
      "70/214\n",
      "71/214\n",
      "72/214\n",
      "73/214\n",
      "74/214\n",
      "75/214\n",
      "76/214\n",
      "77/214\n",
      "78/214\n",
      "79/214\n",
      "80/214\n",
      "81/214\n",
      "82/214\n",
      "83/214\n",
      "84/214\n",
      "85/214\n",
      "86/214\n",
      "87/214\n",
      "88/214\n",
      "89/214\n",
      "90/214\n",
      "91/214\n",
      "92/214\n",
      "93/214\n",
      "94/214\n",
      "95/214\n",
      "96/214\n",
      "97/214\n",
      "98/214\n",
      "99/214\n",
      "100/214\n",
      "101/214\n",
      "102/214\n",
      "103/214\n",
      "104/214\n",
      "105/214\n",
      "106/214\n",
      "107/214\n",
      "108/214\n",
      "109/214\n",
      "110/214\n",
      "111/214\n",
      "112/214\n",
      "113/214\n",
      "114/214\n",
      "115/214\n",
      "116/214\n",
      "117/214\n",
      "118/214\n",
      "119/214\n",
      "120/214\n",
      "121/214\n",
      "122/214\n",
      "123/214\n",
      "124/214\n",
      "125/214\n",
      "126/214\n",
      "127/214\n",
      "128/214\n",
      "129/214\n",
      "130/214\n",
      "131/214\n",
      "132/214\n",
      "133/214\n",
      "134/214\n",
      "135/214\n",
      "136/214\n",
      "137/214\n",
      "138/214\n",
      "139/214\n",
      "140/214\n",
      "141/214\n",
      "142/214\n",
      "143/214\n",
      "144/214\n",
      "145/214\n",
      "146/214\n",
      "147/214\n",
      "148/214\n",
      "149/214\n",
      "150/214\n",
      "151/214\n",
      "152/214\n",
      "153/214\n",
      "154/214\n",
      "155/214\n",
      "156/214\n",
      "157/214\n",
      "158/214\n",
      "159/214\n",
      "160/214\n",
      "161/214\n",
      "162/214\n",
      "163/214\n",
      "164/214\n",
      "165/214\n",
      "166/214\n",
      "167/214\n",
      "168/214\n",
      "169/214\n",
      "170/214\n",
      "171/214\n",
      "172/214\n",
      "173/214\n",
      "174/214\n",
      "175/214\n",
      "176/214\n",
      "177/214\n",
      "178/214\n",
      "179/214\n",
      "180/214\n",
      "181/214\n",
      "182/214\n",
      "183/214\n",
      "184/214\n",
      "185/214\n",
      "186/214\n",
      "187/214\n",
      "188/214\n",
      "189/214\n",
      "190/214\n",
      "191/214\n",
      "192/214\n",
      "193/214\n",
      "194/214\n",
      "195/214\n",
      "196/214\n",
      "197/214\n",
      "198/214\n",
      "199/214\n",
      "200/214\n",
      "201/214\n",
      "202/214\n",
      "203/214\n",
      "204/214\n",
      "205/214\n",
      "206/214\n",
      "207/214\n",
      "208/214\n",
      "209/214\n",
      "210/214\n",
      "211/214\n",
      "212/214\n",
      "213/214\n",
      "214/214\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame() #Initialize the dataframe\n",
    "j = 1\n",
    "mth = 5\n",
    "dy = 1\n",
    "for item in urls:\n",
    "    html = opener.open(item)\n",
    "    bsObj = bs(html.read(), \"html5lib\") #bsObj is a BeautifulSoup Object that contains the entire html file data\n",
    "    bs_table = bsObj.find(\"table\", {\"id\":\"obsTable\"}) #bs_table is a table with the id 'obsTable', extracted from bsObj\n",
    "    tbl_list = []\n",
    "\n",
    "    #Go through each bs_table cell with the tag <tr> and copy it into a 2x2 table 'tbl_list'\n",
    "    for row in bs_table.findAll(\"tr\"):\n",
    "        tmp_list = [] #tmp_list represents the current row we are building\n",
    "        for item in row:\n",
    "            try:\n",
    "                string = item.get_text().strip()\n",
    "                s=\"\"\n",
    "                for c in string:\n",
    "                    if c.isdigit() or c.isalpha() or c==r\".\" or c==r\" \" or c==\"(\" or c==\")\" or c==\":\": #only these characters are allowed\n",
    "                        s += c\n",
    "                    else:\n",
    "                        break #the moment you encounter an invalid character, stop reading and move on to the next item in the row\n",
    "                tmp_list.append(s)\n",
    "            except:\n",
    "                pass\n",
    "        tbl_list.append(tmp_list)\n",
    "\n",
    "    # temporarily transpose the columns to become rows so that I can remove the irrelevant columns\n",
    "    tbl_list = transpose(tbl_list)\n",
    "\n",
    "    newlist = [] #Because python is acting fucked up, instead of removing all columns that are not \"Time\", \"Temp\" or \"Humidity\" I have to create a new list and append the \"Time\", \"Temp\" & \"Humidity\" columns to it\n",
    "    #while tbl_list contains every column, newlist only contains the \"Time (CST)\", \"Temp.\" and \"Humidity\" columns\n",
    "    for i in tbl_list:\n",
    "        if (i[0] == r\"Time (CST)\" or i[0] == r\"Temp.\" or i[0] == r\"Humidity\"):\n",
    "            newlist.append(i)\n",
    "\n",
    "    #add the corresponding date to every time entry\n",
    "    newlist[0] = [\"2017/\" + str(mth) + \"/\" + str(dy) + \" \" + time if time != \"Time (CST)\" else time for time in newlist[0]]\n",
    "    #and then increment the date counter\n",
    "    if (mth==6 or mth==9 or mth==11):\n",
    "        if (dy>=30):\n",
    "            mth += 1\n",
    "            dy = 1\n",
    "        else:\n",
    "            dy += 1\n",
    "    else:\n",
    "        if (dy>=31):\n",
    "            mth += 1\n",
    "            dy = 1\n",
    "        else:\n",
    "            dy += 1\n",
    "\n",
    "    newlist = transpose(newlist) #transpose it back\n",
    "    df=df.append(pd.DataFrame(newlist)) #append the table for this url page to the overall dataframe\n",
    "    print(str(j) + \"/\" + str(len(urls))) #progress counter\n",
    "    j += 1\n",
    "#for loop ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time (CST)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017/5/1 12:00 AM</th>\n",
       "      <td>22.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 1:00 AM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 2:00 AM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 3:00 AM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 4:00 AM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 5:00 AM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 6:00 AM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 6:30 AM</th>\n",
       "      <td>22.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 7:00 AM</th>\n",
       "      <td>24.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 7:30 AM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 8:00 AM</th>\n",
       "      <td>26.0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 8:30 AM</th>\n",
       "      <td>27.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 9:00 AM</th>\n",
       "      <td>28.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 9:30 AM</th>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 10:00 AM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 10:30 AM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 11:00 AM</th>\n",
       "      <td>31.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 11:30 AM</th>\n",
       "      <td>31.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 12:00 PM</th>\n",
       "      <td>31.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 12:30 PM</th>\n",
       "      <td>31.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 1:00 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 1:01 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 1:30 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 2:00 PM</th>\n",
       "      <td>31.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 2:30 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 3:00 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 3:30 PM</th>\n",
       "      <td>30.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 4:00 PM</th>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 4:30 PM</th>\n",
       "      <td>29.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/5/1 5:00 PM</th>\n",
       "      <td>28.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 7:00 AM</th>\n",
       "      <td>22.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 7:30 AM</th>\n",
       "      <td>23.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 8:00 AM</th>\n",
       "      <td>23.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 8:30 AM</th>\n",
       "      <td>24.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 9:00 AM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 9:30 AM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 9:39 AM</th>\n",
       "      <td>26.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 10:00 AM</th>\n",
       "      <td>26.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 10:16 AM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 10:30 AM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 11:00 AM</th>\n",
       "      <td>26.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 11:30 AM</th>\n",
       "      <td>24.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 12:00 PM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 12:30 PM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 1:30 PM</th>\n",
       "      <td>25.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 2:00 PM</th>\n",
       "      <td>24.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 2:30 PM</th>\n",
       "      <td>24.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 3:00 PM</th>\n",
       "      <td>23.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 4:00 PM</th>\n",
       "      <td>22.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 5:30 PM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 6:00 PM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 6:30 PM</th>\n",
       "      <td>21.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 7:00 PM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 8:00 PM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 8:30 PM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 9:30 PM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 10:00 PM</th>\n",
       "      <td>20.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 10:30 PM</th>\n",
       "      <td>19.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 11:00 PM</th>\n",
       "      <td>19.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/11/30 11:30 PM</th>\n",
       "      <td>19.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                   Temp. Humidity\n",
       "Time (CST)                        \n",
       "2017/5/1 12:00 AM    22.0       73\n",
       "2017/5/1 1:00 AM     21.0       78\n",
       "2017/5/1 2:00 AM     21.0       78\n",
       "2017/5/1 3:00 AM     21.0       78\n",
       "2017/5/1 4:00 AM     20.0       78\n",
       "2017/5/1 5:00 AM     20.0       78\n",
       "2017/5/1 6:00 AM     21.0       73\n",
       "2017/5/1 6:30 AM     22.0       73\n",
       "2017/5/1 7:00 AM     24.0       69\n",
       "2017/5/1 7:30 AM     25.0       65\n",
       "2017/5/1 8:00 AM     26.0       65\n",
       "2017/5/1 8:30 AM     27.0       61\n",
       "2017/5/1 9:00 AM     28.0       54\n",
       "2017/5/1 9:30 AM     29.0       48\n",
       "2017/5/1 10:00 AM    30.0       40\n",
       "2017/5/1 10:30 AM    30.0       45\n",
       "2017/5/1 11:00 AM    31.0       46\n",
       "2017/5/1 11:30 AM    31.0       46\n",
       "2017/5/1 12:00 PM    31.0       46\n",
       "2017/5/1 12:30 PM    31.0       49\n",
       "2017/5/1 1:00 PM     30.0       51\n",
       "2017/5/1 1:01 PM     30.0       55\n",
       "2017/5/1 1:30 PM     30.0       55\n",
       "2017/5/1 2:00 PM     31.0       52\n",
       "2017/5/1 2:30 PM     30.0       51\n",
       "2017/5/1 3:00 PM     30.0       48\n",
       "2017/5/1 3:30 PM     30.0       45\n",
       "2017/5/1 4:00 PM     29.0       48\n",
       "2017/5/1 4:30 PM     29.0       55\n",
       "2017/5/1 5:00 PM     28.0       58\n",
       "...                   ...      ...\n",
       "2017/11/30 7:00 AM   22.0       88\n",
       "2017/11/30 7:30 AM   23.0       88\n",
       "2017/11/30 8:00 AM   23.0       83\n",
       "2017/11/30 8:30 AM   24.0       83\n",
       "2017/11/30 9:00 AM   25.0       78\n",
       "2017/11/30 9:30 AM   25.0       78\n",
       "2017/11/30 9:39 AM   26.0       74\n",
       "2017/11/30 10:00 AM  26.0       74\n",
       "2017/11/30 10:16 AM  25.0       78\n",
       "2017/11/30 10:30 AM  25.0       78\n",
       "2017/11/30 11:00 AM  26.0       74\n",
       "2017/11/30 11:30 AM  24.0       83\n",
       "2017/11/30 12:00 PM  25.0       78\n",
       "2017/11/30 12:30 PM  25.0       78\n",
       "2017/11/30 1:30 PM   25.0       74\n",
       "2017/11/30 2:00 PM   24.0       78\n",
       "2017/11/30 2:30 PM   24.0       78\n",
       "2017/11/30 3:00 PM   23.0       78\n",
       "2017/11/30 4:00 PM   22.0       83\n",
       "2017/11/30 5:30 PM   21.0       88\n",
       "2017/11/30 6:00 PM   21.0       88\n",
       "2017/11/30 6:30 PM   21.0       88\n",
       "2017/11/30 7:00 PM   20.0       94\n",
       "2017/11/30 8:00 PM   20.0       94\n",
       "2017/11/30 8:30 PM   20.0       94\n",
       "2017/11/30 9:30 PM   20.0       88\n",
       "2017/11/30 10:00 PM  20.0       88\n",
       "2017/11/30 10:30 PM  19.0       94\n",
       "2017/11/30 11:00 PM  19.0       94\n",
       "2017/11/30 11:30 PM  19.0       94\n",
       "\n",
       "[10205 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the header and column index\n",
    "df.columns = df.iloc[0] #set the first row as the header row (which determines the column names)\n",
    "df = df.drop_duplicates(subset=\"Time (CST)\", keep=False) #delete all the useless duplicate header rows ('Time', 'Temp' & 'Humidity')in the table data\n",
    "df = df.set_index(\"Time (CST)\") #set the first column as index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Temp.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Temp.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7a01bc45c363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#normalize all time to hours, e.g 6.30PM becomes 6.00PM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0;31m#this will introduce duplicates datetime entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Temp.'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Temp.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#I can use to_numeric to convert a column of strings to numbers,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Humidity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Humidity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Or I can use a simple lamba function to do the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time (CST)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#aggregate the duplicate entries by taking their mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Temp.'"
     ]
    }
   ],
   "source": [
    "#getting the hourly average\n",
    "df.index=pd.DatetimeIndex(df.index) #convert date index datatype to DateTime\n",
    "df.index=df.index.map(lambda x:x.replace(minute=0)) #normalize all time to hours, e.g 6.30PM becomes 6.00PM\n",
    "                                                    #this will introduce duplicates datetime entries\n",
    "df['Temp.'] = df['Temp.'].apply(pd.to_numeric, errors='ignore') #I can use to_numeric to convert a column of strings to numbers,\n",
    "df['Humidity'] = df['Humidity'].apply(lambda x: int(x)) #Or I can use a simple lamba function to do the same\n",
    "df = df.groupby('Time (CST)').mean() #aggregate the duplicate entries by taking their mean\n",
    "df['Humidity'] = df['Humidity'].apply(lambda x: int(x)) #mean() converts humidity column data to floats, so convert them back to int\n",
    "df.columns = [\"Temp/°C\", \"Humidity/%\"] #Add units to column headers\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5112 entries, 2017-05-01 00:00:00 to 2017-11-30 23:00:00\n",
      "Data columns (total 2 columns):\n",
      "Temp/°C       5112 non-null float64\n",
      "Humidity/%    5112 non-null int64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 119.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#May-Nov has (31 + 30 + 31 + 31 + 30 + 31 + 30)(24) = 5136 hours in total. There should be 5136 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file \"Weather Data (May-Nov)(Hourly).csv\" has been created in the current folder.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('./Weather Data (May-Nov)(Hourly).csv')\n",
    "print('The file \"Weather Data (May-Nov)(Hourly).csv\" has been created in the current folder.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
